{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyper-Scale Machine Learning with MinIO and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are living in a transformative era defined by information and AI. Massive amounts of data are generated and collected every day to feed these voracious, state-of-the-art, AI/ML algorithms. The more data, the better the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "One of the frameworks that has emerged as the lead industry standards is [Google's TensorFlow](https://www.tensorflow.org/).  Highly versatile, one can get started quickly and write simple models with their [Keras](https://www.tensorflow.org/guide/keras?hl=en) framework. If you seek a more advanced approach TensorFlow also allows you to construct your own machine learning models using low level APIs. No matter what strategy you choose, TensorFlow will make sure that your algorithm gets optimized for whatever infrastructure you select for your algorithms - whether it's [CPU's](https://en.wikipedia.org/wiki/Central_processing_unit), [GPU's](https://en.wikipedia.org/wiki/Graphics_processing_unit) or [TPU's](https://en.wikipedia.org/wiki/Tensor_processing_unit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As datasets become too large to fit into memory or local disk, AI/ML pipelines now have the requirement to load data from an external data source. Take for example the [ImageNet](https://en.wikipedia.org/wiki/ImageNet) dataset with its `14 Million` Images with an estimated storage size of `1.31TB`. This dataset cannot be fit into memory nor on any machine local storage drive. These challenges are further complicated if your pipelines are running inside a stateless environment such a Kubernetes (which is increasingly the norm). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The emerging standard for this problem is to employ high performance object storage in the design of your AI/ML pipelines. MinIO is the leader in this space and has published a number of benchmarks that speak to its throughput capabilities. In this post, we will cover how to leverage MinIO for your TensorFlow projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## A Five Stage Hyper-Scale Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To build a hyper-scale pipeline we will have each stage of the pipeline read from MinIO. In this example we are going to build four stages of a machine learning pipeline. This architecture will load the desired data on-demand from MinIO. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we are going to preprocess our dataset and encode it in a format that TensorFlow can quickly digest. This format is the [tf.TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord), which is a type of binary encoding for our data. We are taking this step because we do not want to waste time processing the data during the training as we are planning on loading each batch of training directly from MinIO as it's needed. If the data is pre-processed before we feed it into the model training we save a significant amount of time. Ideally, we create pre-processed chunks of data that group a good chunk of records - at least `100-200MB` in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To speed up the data-loading and training stages we are going to leverage the excellent [tf.data](https://www.tensorflow.org/api_docs/python/tf/data) api. This API is designed to efficiently load data during the training/validation of our model. It prepares the next batch of data as the current one is being processed by the model. The advantage of this approach is that it ensures efficient utilization of expensive GPUs or TPUs which cannot sit idle due to slow loading data. MinIO does not encounter this problem - [it can saturate 100Gbps network with a few NVMe drives](https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-NVMe-SSD-32-Node.pdf) or also with [Hard Disk Drives](https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-HDD-24-Node.pdf) ensuring the pipeline is crunching data as fast as the hardware allows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "During training we want to make sure we store the training checkpoints of our model as well as TensorBoard histograms. The checkpoints are useful in case the training gets interrupted and we want to resume the training or if we get more data and want to keep training our model with the new data and the TensorBoard histograms let us see how the training is going as it happens. TensorFlow supports writing both of these directly to MinIO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A quick side note. When the model is complete we will save it to MinIO as well - allowing us to serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![title](pic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For our hyper-scale pipeline we are going to use a dataset that can easily fit into your local computer so you can follow along. The [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) from Stanford is great since it has a large number of samples (25,000 for training and 25,000 for testing) so we are going to build a [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) model that will tell us whether a movie review is `positive` or `negative`. Keep in mind that each step can be applied to any larger dataset. The advantage of this dataset is that you can try on your own computer. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to use the [minio client cli tool](https://docs.min.io/docs/minio-client-quickstart-guide.html), also known as `mc` and refer to our MinIO instance as the `myminio` alias. You can download it at [MinIO's Website](https://min.io/download#/linux)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's configure our `mc`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[m\u001B[32mAdded `myminio` successfully.\u001B[0m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!mc config host add myminio http://{minio_address} {minio_access_key} {minio_secret_key}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create our bucket if it doesn't exist already, alternative you can create it using the [MinIO Console](https://docs.min.io/minio/baremetal/console/minio-console.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download the dataset and upload it to MinIO using [MinIO Client](https://docs.min.io/docs/minio-client-quickstart-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "!curl -s http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz | mc pipe myminio/{datasets_bucket}/aclImdb_v1.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start by declaring some configurations for our pipeline,  such as `batch size`, location of our dataset and a fixed `random seed` so we can run this pipeline again and again and get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import tarfile\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 44\n",
    "batch_size = 128\n",
    "datasets_bucket = \"datasets\"\n",
    "preprocessed_data_folder = \"preprocessed-data\"\n",
    "tf_record_file_size = 500\n",
    "# How to access MinIO\n",
    "# minio_address = \"localhost:9000\"\n",
    "# TODO: REMOVE ME, THIS IS MY LOCAL ENV :-)\n",
    "minio_address = \"192.168.86.197:9000\"\n",
    "minio_access_key = \"minioadmin\"\n",
    "minio_secret_key = \"minioadmin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are going to download our dataset from MinIO using [minio-py](https://github.com/minio/minio-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "minioClient = Minio(minio_address,\n",
    "                  access_key=minio_access_key,\n",
    "                  secret_key=minio_secret_key,\n",
    "                  secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "       minioClient.fget_object(\n",
    "           datasets_bucket,\n",
    "           \"aclImdb_v1.tar.gz\",\n",
    "           \"/tmp/dataset.tar.gz\")\n",
    "except S3Error as err:\n",
    "       print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's uncompress the dataset to a temporary folder (`/tmp/dataset`) to preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extract_folder = f\"/tmp/{datasets_bucket}/\"\n",
    "\n",
    "with tarfile.open(\"/tmp/dataset.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to the structure of the dataset we are going to read from four folders, initially `test` and `train` which hold `25,000` examples each, then, in each of those folders we have `12,500` of each label pos for positive comments and neg for negative comments. From these four folders, we are going to store all samples into two variables, `train` and `test`. If we were preprocessing a dataset that couldn't fit in the local machine we could simply load segments of the object, one at a time and process them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "\n",
    "dirs_to_read = [\n",
    "    \"aclImdb/train/pos\",\n",
    "    \"aclImdb/train/neg\",\n",
    "    \"aclImdb/test/pos\",\n",
    "    \"aclImdb/test/neg\",\n",
    "]\n",
    "\n",
    "for dir_name in dirs_to_read:\n",
    "    parts = dir_name.split(\"/\")\n",
    "    dataset = parts[1]\n",
    "    label = parts[2]\n",
    "    for filename in os.listdir(os.path.join(extract_folder,dir_name)):\n",
    "        with open(os.path.join(extract_folder,dir_name,filename),\"r\") as f:\n",
    "            content = f.read()\n",
    "            if dataset == \"train\":\n",
    "                train.append({\n",
    "                    \"text\":content,\n",
    "                    \"label\":label\n",
    "                })\n",
    "            elif dataset == \"test\":\n",
    "                test.append({\n",
    "                    \"text\":content,\n",
    "                    \"label\":label\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will then shuffle the dataset so we don't introduce bias into the training by providing 12,500 consecutive positive examples followed by 12,500 consecutive negative examples. Our model would have a hard time generalizing that. By shuffling the data the model will get to see and learn from both positive and negative examples at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random.Random(random_seed).shuffle(train)\n",
    "random.Random(random_seed).shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we are dealing with text we need to turn the text to a vector representation that accurately depicts the meanings of the sentence. If we were dealing with images we would resize the images and turn them into vector representations having each pixel be a value of the resized image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For text, however, we have a bigger challenge since a word doesn't really have a numerical representation. This is where [embeddings](https://en.wikipedia.org/wiki/Embedding) are useful. An embedding is a vector representation of some text, in this case we are going to represent the whole review as a single vector of 512 dimensions. Instead of doing the pre-processing of text manually (tokenizing, building vocabulary and training an embeddings layer) we are going to leverage an existing model called [USE (Universal Sentence Encoder)](https://arxiv.org/abs/1803.11175) to encode sentences into vectors so we can continue with our example. This is one of the wonders of deep learning, the ability to re-use different models alongside yours. Here we use TensorFlow Hub and we are going to load the latest `USE` model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are going to be using this model often, we'll download the model and store it in our `datasets` bucket and use it from there whenever we need it, avoiding a download from the internet every time we run this pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "!curl -s https://storage.googleapis.com/tfhub-modules/google/universal-sentence-encoder/4.tar.gz | mc pipe myminio/{datasets_bucket}/models/universal-sentence-encoder_4.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now download the data and load it as a model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "try:\n",
    "    minioClient.fget_object(\n",
    "        datasets_bucket,\n",
    "        \"models/universal-sentence-encoder_4.tar.gz\",\n",
    "        \"/tmp/universal-sentence-encoder_4.tar.gz\")\n",
    "except S3Error as err:\n",
    "    print(err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "se_model_prefix = \"universal-sentence-encoder/4\"\n",
    "extract_folder = f\"/tmp/{se_model_prefix}/\"\n",
    "\n",
    "with tarfile.open(\"/tmp/universal-sentence-encoder_4.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 16:55:37.629408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-12 16:55:37.667498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 16:55:37.667815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-08-12 16:55:37.668219: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2022-08-12 16:55:37.668413: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2022-08-12 16:55:37.672588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-12 16:55:37.674632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-12 16:55:37.674761: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2022-08-12 16:55:37.674958: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2022-08-12 16:55:37.675178: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2022-08-12 16:55:37.675192: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-12 16:55:37.675607: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-08-12 16:55:37.707977: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2599990000 Hz\n",
      "2022-08-12 16:55:37.708473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc338000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-12 16:55:37.708491: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-08-12 16:55:37.710406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-12 16:55:37.710420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n"
     ]
    }
   ],
   "source": [
    "embed = tf.saved_model.load(extract_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since it would be too much to create the embeddings of `25,000` sentences and keep that in memory, we are going to slice our datasets into chunks of `500`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To store our data into a `TFRecord` we need to encode the features as `tf.train.Feature`.  We are going to store the label of our data as list of tf.int64 and our Movie Review as a list of floats since after we encode the sentence using `USE` we will end-up with a embedding of `512` dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _embedded_sentence_feature(value):\n",
    "    # convert tensor to list of float values\n",
    "    input = value.numpy().ravel().tolist()\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=input))\n",
    "def _label_feature(value):\n",
    "    # convert tensor to list of float values\n",
    "    input = value.numpy().ravel().tolist()\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    if label == \"pos\":\n",
    "        return tf.constant([1,0])\n",
    "    elif label == \"neg\":\n",
    "        return tf.constant([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def serialize_example(label, sentence_tensor):\n",
    "    feature = {\n",
    "      \"sentence\": _embedded_sentence_feature(sentence_tensor[0]),\n",
    "      \"label\": _label_feature(label),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 25000 elements\n",
      "Total of 50 files of 500 records - 0.00016006804071366787\n",
      "Done serializing example ( 0.002772710984572768 - 4.093500319868326e-05 - 0.00041163002606481314 ). Buffer 500 - 1.923315469990484454\n",
      "Records in buffer 500 - 1.9233435740461573\n",
      "done write example file, size 946889 - 1.9938666310627013\n",
      "Done with batch 1/50 - 2.02170073101297\n",
      "Done serializing example ( 0.00206570397131145 - 3.561703488230705e-05 - 0.0003728069132193923 ). Buffer 500 - 3.55506311298813673447\n",
      "Records in buffer 500 - 3.55509174708277\n",
      "done write example file, size 946826 - 3.620114278048277\n",
      "Done with batch 2/50 - 3.646042542066425\n",
      "Done serializing example ( 0.002934725023806095 - 4.390196409076452e-05 - 0.0004615799989551306 ). Buffer 500 - 5.2137905790004883155\n",
      "Records in buffer 500 - 5.213819964090362\n",
      "done write example file, size 946692 - 5.280126277008094\n",
      "Done with batch 3/50 - 5.310235252021812\n",
      "Done serializing example ( 0.002282477915287018 - 3.935699351131916e-05 - 0.0003773040371015668 ). Buffer 500 - 6.8150406579952699355\n",
      "Records in buffer 500 - 6.815069010015577\n",
      "done write example file, size 947395 - 6.893179291044362\n",
      "Done with batch 4/50 - 6.924159932998009\n",
      "Done serializing example ( 0.00291662709787488 - 4.1341991163790226e-05 - 0.00040160492062568665 ). Buffer 500 - 8.433481730986387374\n",
      "Records in buffer 500 - 8.433509957045317\n",
      "done write example file, size 946852 - 8.512406488065608\n",
      "Done with batch 5/50 - 8.540189045015723\n",
      "Done serializing example ( 0.002064031083136797 - 3.299093805253506e-05 - 0.00040091003756970167 ). Buffer 500 - 10.0102587289875374\n",
      "Records in buffer 500 - 10.010286860051565\n",
      "done write example file, size 947298 - 10.075005596037954\n",
      "Done with batch 6/50 - 10.10052890505176\n",
      "Done serializing example ( 0.0025735209928825498 - 5.173508543521166e-05 - 0.0005985279567539692 ). Buffer 500 - 11.64517630403861453\n",
      "Records in buffer 500 - 11.64521702809725\n",
      "done write example file, size 946717 - 11.711916552041657\n",
      "Done with batch 7/50 - 11.737990639056079\n",
      "Done serializing example ( 0.002103070029988885 - 3.9268983528018e-05 - 0.0003903430188074708 ). Buffer 500 - 13.26468643406406744744\n",
      "Records in buffer 500 - 13.2647164670052\n",
      "done write example file, size 947238 - 13.331317624077201\n",
      "Done with batch 8/50 - 13.35710718901828\n",
      "Done serializing example ( 0.00704544794280082 - 6.011303048580885e-05 - 0.000632370007224381 ). Buffer 500 - 14.86635603406466561966\n",
      "Records in buffer 500 - 14.866401614039205\n",
      "done write example file, size 947170 - 14.947197995032184\n",
      "Done with batch 9/50 - 14.97475774306804\n",
      "Done serializing example ( 0.001903499010950327 - 3.2051000744104385e-05 - 0.000371903064660728 ). Buffer 500 - 16.461321504088121445\n",
      "Records in buffer 500 - 16.461348795099184\n",
      "done write example file, size 946819 - 16.53402670309879\n",
      "Done with batch 10/50 - 16.57264337001834\n",
      "Done serializing example ( 0.0031857159920036793 - 5.003693513572216e-05 - 0.00040138501208275557 ). Buffer 500 - 18.1310454810736767\n",
      "Records in buffer 500 - 18.131074996083044\n",
      "done write example file, size 946940 - 18.196957660024054\n",
      "Done with batch 11/50 - 18.22215786599554\n",
      "Done serializing example ( 0.0025300009874626994 - 3.923103213310242e-05 - 0.0003805019659921527 ). Buffer 500 - 19.75526899308897635\n",
      "Records in buffer 500 - 19.755297322990373\n",
      "done write example file, size 946807 - 19.82217020506505\n",
      "Done with batch 12/50 - 19.846200664062053\n",
      "Done serializing example ( 0.0033351650927215815 - 4.226597957313061e-05 - 0.00039987394120544195 ). Buffer 500 - 21.4027036880143187\n",
      "Records in buffer 500 - 21.402732798014767\n",
      "done write example file, size 947066 - 21.482894691987894\n",
      "Done with batch 13/50 - 21.509479450061917\n",
      "Done serializing example ( 0.0022831029491499066 - 4.0275976061820984e-05 - 0.0004041430074721575 ). Buffer 500 - 23.0688712020637474\n",
      "Records in buffer 500 - 23.068899938021787\n",
      "done write example file, size 947023 - 23.136448817094788\n",
      "Done with batch 14/50 - 23.16525601700414\n",
      "Done serializing example ( 0.005172763019800186 - 6.765394937247038e-05 - 0.0006155830342322588 ). Buffer 500 - 25.006176870083436276\n",
      "Records in buffer 500 - 25.00622156704776\n",
      "done write example file, size 946945 - 25.07800178800244\n",
      "Done with batch 15/50 - 25.10943340708036\n",
      "Done serializing example ( 0.0020749979885295033 - 3.4725992009043694e-05 - 0.00040206301491707563 ). Buffer 500 - 26.587726432015188\n",
      "Records in buffer 500 - 26.58775514003355\n",
      "done write example file, size 946922 - 26.660775094060227\n",
      "Done with batch 16/50 - 26.68759012001101\n",
      "Done serializing example ( 0.0018888229969888926 - 3.395101521164179e-05 - 0.00039040599949657917 ). Buffer 500 - 28.2052582280011855\n",
      "Records in buffer 500 - 28.205286976066418\n",
      "done write example file, size 947170 - 28.269474192988127\n",
      "Done with batch 17/50 - 28.295655262074433\n",
      "Done serializing example ( 0.0018841199344024062 - 3.661401569843292e-05 - 0.00037929299287497997 ). Buffer 500 - 29.8436945950379687\n",
      "Records in buffer 500 - 29.843723564059474\n",
      "done write example file, size 946750 - 29.91028350603301\n",
      "Done with batch 18/50 - 29.936817885027267\n",
      "Done serializing example ( 0.003778441925533116 - 4.621304105967283e-05 - 0.00045675504952669144 ). Buffer 500 - 31.52053377206903743\n",
      "Records in buffer 500 - 31.520572500070557\n",
      "done write example file, size 946600 - 31.601408690097742\n",
      "Done with batch 19/50 - 31.631552873994224\n",
      "Done serializing example ( 0.003157370025292039 - 4.4020009227097034e-05 - 0.0005793549353256822 ). Buffer 500 - 33.18804482009727535\n",
      "Records in buffer 500 - 33.18807472707704\n",
      "done write example file, size 946707 - 33.25445587502327\n",
      "Done with batch 20/50 - 33.280622164020315\n",
      "Done serializing example ( 0.002086991094984114 - 3.585894592106342e-05 - 0.0003765870351344347 ). Buffer 500 - 34.824633080046624666\n",
      "Records in buffer 500 - 34.82466177502647\n",
      "done write example file, size 947322 - 34.892232292098925\n",
      "Done with batch 21/50 - 34.918298745993525\n",
      "Done serializing example ( 0.0026965169236063957 - 4.110299050807953e-05 - 0.00042013206984847784 ). Buffer 500 - 36.4055718980962465\n",
      "Records in buffer 500 - 36.40560074802488\n",
      "done write example file, size 947233 - 36.47128993505612\n",
      "Done with batch 22/50 - 36.49661173205823\n",
      "Done serializing example ( 0.0026341238990426064 - 3.819901030510664e-05 - 0.00040196802001446486 ). Buffer 500 - 38.1137239200761545\n",
      "Records in buffer 500 - 38.113752554985695\n",
      "done write example file, size 946869 - 38.195087735075504\n",
      "Done with batch 23/50 - 38.22699970798567\n",
      "Done serializing example ( 0.0021561840549111366 - 3.696500789374113e-05 - 0.00039838801603764296 ). Buffer 500 - 39.7978635210311046\n",
      "Records in buffer 500 - 39.79789248504676\n",
      "done write example file, size 947030 - 39.877949784044176\n",
      "Done with batch 24/50 - 39.90214677900076\n",
      "Done serializing example ( 0.0022581189405173063 - 4.070007707923651e-05 - 0.00038630596827715635 ). Buffer 500 - 41.5260891440557325\n",
      "Records in buffer 500 - 41.5261256180238\n",
      "done write example file, size 944673 - 41.607155195088126\n",
      "Done with batch 25/50 - 41.63345454004593\n",
      "Done serializing example ( 0.0021559190936386585 - 3.550900146365166e-05 - 0.00042139599099755287 ). Buffer 500 - 43.1932748541003164\n",
      "Records in buffer 500 - 43.1933038480347\n",
      "done write example file, size 946944 - 43.25774484104477\n",
      "Done with batch 26/50 - 43.28356947703287\n",
      "Done serializing example ( 0.002014043042436242 - 3.723497502505779e-05 - 0.000419207033701241 ). Buffer 500 - 44.7825842800084565104\n",
      "Records in buffer 500 - 44.782612605020404\n",
      "done write example file, size 946962 - 44.84920738299843\n",
      "Done with batch 27/50 - 44.87685295508709\n",
      "Done serializing example ( 0.0030425259610638022 - 3.9541046135127544e-05 - 0.0003894160035997629 ). Buffer 500 - 46.3499879559967764\n",
      "Records in buffer 500 - 46.35001552302856\n",
      "done write example file, size 947107 - 46.41772749403026\n",
      "Done with batch 28/50 - 46.4447898210492\n",
      "Done serializing example ( 0.00228711508680135 - 5.299295298755169e-05 - 0.00043738295789808035 ). Buffer 500 - 48.007297166041123964\n",
      "Records in buffer 500 - 48.00732993404381\n",
      "done write example file, size 946813 - 48.08848239702638\n",
      "Done with batch 29/50 - 48.11462157499045\n",
      "Done serializing example ( 0.005359590984880924 - 5.418702494353056e-05 - 0.0004557219799607992 ). Buffer 500 - 49.668947083991953955\n",
      "Records in buffer 500 - 49.668976932996884\n",
      "done write example file, size 946530 - 49.73547046200838\n",
      "Done with batch 30/50 - 49.76172847603448\n",
      "Done serializing example ( 0.0031014980049803853 - 4.1733961552381516e-05 - 0.0003998850006610155 ). Buffer 500 - 51.2851718410383966\n",
      "Records in buffer 500 - 51.28520090505481\n",
      "done write example file, size 947197 - 51.35668984404765\n",
      "Done with batch 31/50 - 51.38529683300294\n",
      "Done serializing example ( 0.0034361929865553975 - 5.710194818675518e-05 - 0.0005555490497499704 ). Buffer 500 - 52.91373743698932864\n",
      "Records in buffer 500 - 52.91376773302909\n",
      "done write example file, size 946875 - 52.98120570008177\n",
      "Done with batch 32/50 - 53.008564343093894\n",
      "Done serializing example ( 0.002154513029381633 - 3.589701373130083e-05 - 0.0005137500120326877 ). Buffer 500 - 54.516285345074726145\n",
      "Records in buffer 500 - 54.516313231084496\n",
      "done write example file, size 946516 - 54.58309027098585\n",
      "Done with batch 33/50 - 54.61588375607971\n",
      "Done serializing example ( 0.001917629037052393 - 3.6190031096339226e-05 - 0.0003647229168564081 ). Buffer 500 - 56.15498446905985556\n",
      "Records in buffer 500 - 56.15501304005738\n",
      "done write example file, size 946797 - 56.21945247007534\n",
      "Done with batch 34/50 - 56.247931126039475\n",
      "Done serializing example ( 0.002137793111614883 - 3.979494795203209e-05 - 0.000416732975281775 ). Buffer 500 - 57.7812545400811364164\n",
      "Records in buffer 500 - 57.78128396207467\n",
      "done write example file, size 946686 - 57.86145619209856\n",
      "Done with batch 35/50 - 57.88913761405274\n",
      "Done serializing example ( 0.0020690789679065347 - 3.4801079891622066e-05 - 0.00037555594462901354 ). Buffer 500 - 59.460518268053426\n",
      "Records in buffer 500 - 59.46054867503699\n",
      "done write example file, size 946963 - 59.527410509996116\n",
      "Done with batch 36/50 - 59.55329644703306\n",
      "Done serializing example ( 0.003039964009076357 - 4.694995004683733e-05 - 0.0005589190404862165 ). Buffer 500 - 61.058434254024183206\n",
      "Records in buffer 500 - 61.05847052508034\n",
      "done write example file, size 946974 - 61.13736327702645\n",
      "Done with batch 37/50 - 61.16851036401931\n",
      "Done serializing example ( 0.002678396995179355 - 5.844596307724714e-05 - 0.0005417619831860065 ). Buffer 500 - 62.710274066077545544\n",
      "Records in buffer 500 - 62.71030876098666\n",
      "done write example file, size 946819 - 62.781894606072456\n",
      "Done with batch 38/50 - 62.81074212805834\n",
      "Done serializing example ( 0.003729560994543135 - 7.513503078371286e-05 - 0.0007379830349236727 ). Buffer 500 - 64.366574669023987574\n",
      "Records in buffer 500 - 64.36665172409266\n",
      "done write example file, size 946668 - 64.43634369503707\n",
      "Done with batch 39/50 - 64.46250625303946\n",
      "Done serializing example ( 0.0022782329469919205 - 3.4705037251114845e-05 - 0.0003861599834635854 ). Buffer 500 - 65.998745164019061\n",
      "Records in buffer 500 - 65.99877288006246\n",
      "done write example file, size 946820 - 66.0649083449971\n",
      "Done with batch 40/50 - 66.0918754870072\n",
      "Done serializing example ( 0.002564505091868341 - 3.8340920582413673e-05 - 0.00041760201565921307 ). Buffer 500 - 67.628918055095716\n",
      "Records in buffer 500 - 67.62894634599797\n",
      "done write example file, size 946653 - 67.71114051807672\n",
      "Done with batch 41/50 - 67.73880050005391\n",
      "Done serializing example ( 0.0021191450068727136 - 3.779900725930929e-05 - 0.0004758919822052121 ). Buffer 500 - 69.2880312990164433\n",
      "Records in buffer 500 - 69.28805971401744\n",
      "done write example file, size 946779 - 69.3549459479982\n",
      "Done with batch 42/50 - 69.38213998300489\n",
      "Done serializing example ( 0.002097498974762857 - 3.3213989809155464e-05 - 0.00038058904465287924 ). Buffer 500 - 70.934413379058245\n",
      "Records in buffer 500 - 70.93444200907834\n",
      "done write example file, size 946976 - 71.00168306007981\n",
      "Done with batch 43/50 - 71.02693942503538\n",
      "Done serializing example ( 0.0025889179669320583 - 3.9732083678245544e-05 - 0.0003867099294438958 ). Buffer 500 - 72.562642044038512\n",
      "Records in buffer 500 - 72.56267816806212\n",
      "done write example file, size 947058 - 72.6314108070219\n",
      "Done with batch 44/50 - 72.66209736699238\n",
      "Done serializing example ( 0.0022372540552169085 - 3.1766947358846664e-05 - 0.00036885403096675873 ). Buffer 500 - 74.20332512306059\n",
      "Records in buffer 500 - 74.20335340604652\n",
      "done write example file, size 946642 - 74.2697512099985\n",
      "Done with batch 45/50 - 74.29753620107658\n",
      "Done serializing example ( 0.0018831940833479166 - 4.0681916289031506e-05 - 0.0004079500213265419 ). Buffer 500 - 75.865467722993348\n",
      "Records in buffer 500 - 75.8654960100539\n",
      "done write example file, size 946801 - 75.93374981102534\n",
      "Done with batch 46/50 - 75.96612727607135\n",
      "Done serializing example ( 0.0022516519529744983 - 4.474108573049307e-05 - 0.0004893949953839183 ). Buffer 500 - 77.5041537070646936\n",
      "Records in buffer 500 - 77.50418102904223\n",
      "done write example file, size 946858 - 77.57615203305613\n",
      "Done with batch 47/50 - 77.603356851032\n",
      "Done serializing example ( 0.004400735953822732 - 4.6664965339004993e-05 - 0.0004269980126991868 ). Buffer 500 - 79.1548784880433214\n",
      "Records in buffer 500 - 79.15490851807408\n",
      "done write example file, size 947085 - 79.22718559298664\n",
      "Done with batch 48/50 - 79.25073884706944\n",
      "Done serializing example ( 0.002987402956932783 - 4.4704065658152103e-05 - 0.00048351497389376163 ). Buffer 500 - 80.765420837095016\n",
      "Records in buffer 500 - 80.76546219701413\n",
      "done write example file, size 946475 - 80.84283231408335\n",
      "Done with batch 49/50 - 80.8709751770366\n",
      "Done serializing example ( 0.0023130099289119244 - 3.761705011129379e-05 - 0.0004098659846931696 ). Buffer 500 - 82.3978160140104643\n",
      "Records in buffer 500 - 82.39784513006452\n",
      "done write example file, size 946797 - 82.48105356201995\n",
      "Done with batch 50/50 - 82.50736962398514\n",
      "\n",
      "total time is : 82.5074547129916\n",
      "Total of 25000 elements\n",
      "Total of 50 files of 500 records - 1.561699900776148e-05\n",
      "Done serializing example ( 0.0043433490209281445 - 5.9586018323898315e-05 - 0.0004525199765339494 ). Buffer 500 - 1.555914671975188264\n",
      "Records in buffer 500 - 1.5559435249306262\n",
      "done write example file, size 947223 - 1.6366563349729404\n",
      "Done with batch 1/50 - 1.6605438669212162\n",
      "Done serializing example ( 0.0023962240666151047 - 3.5616918466985226e-05 - 0.0005091170314699411 ). Buffer 500 - 3.20457028795499356\n",
      "Records in buffer 500 - 3.204611991997808\n",
      "done write example file, size 947050 - 3.271543258917518\n",
      "Done with batch 2/50 - 3.299309813999571\n",
      "Done serializing example ( 0.0018568378873169422 - 2.9583112336695194e-05 - 0.0003579419571906328 ). Buffer 500 - 4.80229358398355515\n",
      "Records in buffer 500 - 4.802320502931252\n",
      "done write example file, size 946856 - 4.868419838952832\n",
      "Done with batch 3/50 - 4.893856526003219\n",
      "Done serializing example ( 0.002563338028267026 - 5.151994992047548e-05 - 0.00041519408114254475 ). Buffer 500 - 6.40957659599371255\n",
      "Records in buffer 500 - 6.409605745924637\n",
      "done write example file, size 947162 - 6.482200925936922\n",
      "Done with batch 4/50 - 6.511953920940869\n",
      "Done serializing example ( 0.0017423669341951609 - 2.9588001780211926e-05 - 0.00035974103957414627 ). Buffer 500 - 8.0692765669664375\n",
      "Records in buffer 500 - 8.06931023101788\n",
      "done write example file, size 947401 - 8.137100253952667\n",
      "Done with batch 5/50 - 8.16569144197274\n",
      "Done serializing example ( 0.0020954000065103173 - 3.627489786595106e-05 - 0.00037750008050352335 ). Buffer 500 - 9.6953294479753828\n",
      "Records in buffer 500 - 9.69535652094055\n",
      "done write example file, size 947260 - 9.778351128916256\n",
      "Done with batch 6/50 - 9.805100588011555\n",
      "Done serializing example ( 0.0034362400183454156 - 5.2141956984996796e-05 - 0.0005328929983079433 ). Buffer 500 - 11.7178975199349221\n",
      "Records in buffer 500 - 11.717938308953308\n",
      "done write example file, size 946939 - 11.808505608001724\n",
      "Done with batch 7/50 - 11.839728983934037\n",
      "Done serializing example ( 0.002950493013486266 - 4.646193701773882e-05 - 0.0004158240044489503 ). Buffer 500 - 13.453528198995627325\n",
      "Records in buffer 500 - 13.453576824977063\n",
      "done write example file, size 947385 - 13.525397071964107\n",
      "Done with batch 8/50 - 13.557564356946386\n",
      "Done serializing example ( 0.003109595039859414 - 3.9495062083005905e-05 - 0.0003989168908447027 ). Buffer 500 - 15.07789379998575958\n",
      "Records in buffer 500 - 15.077922618947923\n",
      "done write example file, size 947125 - 15.151273278985173\n",
      "Done with batch 9/50 - 15.177892550942488\n",
      "Done serializing example ( 0.0029223680030554533 - 5.845108535140753e-05 - 0.0005936059169471264 ). Buffer 500 - 16.74906447296962575\n",
      "Records in buffer 500 - 16.749110340024345\n",
      "done write example file, size 946590 - 16.823755271965638\n",
      "Done with batch 10/50 - 16.853995349956676\n",
      "Done serializing example ( 0.003640822018496692 - 5.188607610762119e-05 - 0.0005122519796714187 ). Buffer 500 - 18.342312622000463468\n",
      "Records in buffer 500 - 18.34237016295083\n",
      "done write example file, size 946992 - 18.415440546930768\n",
      "Done with batch 11/50 - 18.438190036918968\n",
      "Done serializing example ( 0.002229575999081135 - 3.455893602222204e-05 - 0.00037036603316664696 ). Buffer 500 - 20.03342726500705582\n",
      "Records in buffer 500 - 20.03345719294157\n",
      "done write example file, size 946815 - 20.113789933966473\n",
      "Done with batch 12/50 - 20.13901620602701\n",
      "Done serializing example ( 0.002274094964377582 - 3.8928003050386906e-05 - 0.00037436606362462044 ). Buffer 500 - 21.7064636609284272\n",
      "Records in buffer 500 - 21.70650527300313\n",
      "done write example file, size 947084 - 21.77374209393747\n",
      "Done with batch 13/50 - 21.798214601003565\n",
      "Done serializing example ( 0.0027272209990769625 - 4.076294135302305e-05 - 0.0003922460600733757 ). Buffer 500 - 23.36657249997375873\n",
      "Records in buffer 500 - 23.36660121800378\n",
      "done write example file, size 946862 - 23.43383747700136\n",
      "Done with batch 14/50 - 23.45846214692574\n",
      "Done serializing example ( 0.001857505994848907 - 3.4747994504868984e-05 - 0.00046922790352255106 ). Buffer 500 - 25.0243589329766148\n",
      "Records in buffer 500 - 25.024387998972088\n",
      "done write example file, size 946638 - 25.092631457955576\n",
      "Done with batch 15/50 - 25.120266292011365\n",
      "Done serializing example ( 0.002026958973146975 - 3.660796210169792e-05 - 0.0005289349937811494 ). Buffer 500 - 26.692513525020332843\n",
      "Records in buffer 500 - 26.692542345961556\n",
      "done write example file, size 946784 - 26.764254876994528\n",
      "Done with batch 16/50 - 26.799966969992965\n",
      "Done serializing example ( 0.003648953977972269 - 4.384899511933327e-05 - 0.0004250950878486037 ). Buffer 500 - 28.331331640016288455\n",
      "Records in buffer 500 - 28.331378157017753\n",
      "done write example file, size 947259 - 28.40852959791664\n",
      "Done with batch 17/50 - 28.437316895928234\n",
      "Done serializing example ( 0.0020423070527613163 - 3.3415970392525196e-05 - 0.0003636500332504511 ). Buffer 500 - 30.0212269719922945\n",
      "Records in buffer 500 - 30.021254619932733\n",
      "done write example file, size 946945 - 30.102234759018756\n",
      "Done with batch 18/50 - 30.130599613999948\n",
      "Done serializing example ( 0.0025745510356500745 - 3.7812977097928524e-05 - 0.0003997479798272252 ). Buffer 500 - 31.7187348949955784\n",
      "Records in buffer 500 - 31.718763094977476\n",
      "done write example file, size 944858 - 31.786231916979887\n",
      "Done with batch 19/50 - 31.812739911023527\n",
      "Done serializing example ( 0.0026888210559263825 - 4.766997881233692e-05 - 0.00041464599780738354 ). Buffer 500 - 33.3853704920038644\n",
      "Records in buffer 500 - 33.38539943599608\n",
      "done write example file, size 946854 - 33.45789565402083\n",
      "Done with batch 20/50 - 33.48399639199488\n",
      "Done serializing example ( 0.002417291048914194 - 3.617396578192711e-05 - 0.0003943189512938261 ). Buffer 500 - 35.028075361973606365\n",
      "Records in buffer 500 - 35.02810489293188\n",
      "done write example file, size 946898 - 35.096589403925464\n",
      "Done with batch 21/50 - 35.123287508962676\n",
      "Done serializing example ( 0.0026045149425044656 - 3.822403959929943e-05 - 0.00041004898957908154 ). Buffer 500 - 36.6814773819642145\n",
      "Records in buffer 500 - 36.681506249005906\n",
      "done write example file, size 947272 - 36.75116030499339\n",
      "Done with batch 22/50 - 36.782194754923694\n",
      "Done serializing example ( 0.002298601088114083 - 3.463996108621359e-05 - 0.0003804649459198117 ). Buffer 500 - 38.311367666930898764\n",
      "Records in buffer 500 - 38.31141044397373\n",
      "done write example file, size 947078 - 38.38340094301384\n",
      "Done with batch 23/50 - 38.41492770402692\n",
      "Done serializing example ( 0.003718852996826172 - 4.1414983570575714e-05 - 0.00043782603461295366 ). Buffer 500 - 40.0077728190226566\n",
      "Records in buffer 500 - 40.007801186991856\n",
      "done write example file, size 946831 - 40.088083587936126\n",
      "Done with batch 24/50 - 40.11969192896504\n",
      "Done serializing example ( 0.0036400710232555866 - 0.00015600293409079313 - 0.0007009300170466304 ). Buffer 500 - 41.8569451050134414\n",
      "Records in buffer 500 - 41.85699050500989\n",
      "done write example file, size 947041 - 41.92536338896025\n",
      "Done with batch 25/50 - 41.95031679002568\n",
      "Done serializing example ( 0.0023746329825371504 - 4.035199526697397e-05 - 0.0003867750056087971 ). Buffer 500 - 43.53670098993461625\n",
      "Records in buffer 500 - 43.53673135000281\n",
      "done write example file, size 946681 - 43.604605508968234\n",
      "Done with batch 26/50 - 43.629625606001355\n",
      "Done serializing example ( 0.002315924968570471 - 5.057710222899914e-05 - 0.00040578190237283707 ). Buffer 500 - 45.15770749200601754\n",
      "Records in buffer 500 - 45.15773765393533\n",
      "done write example file, size 946821 - 45.22524594201241\n",
      "Done with batch 27/50 - 45.25051696493756\n",
      "Done serializing example ( 0.003209138987585902 - 4.7532026655972004e-05 - 0.000662699923850596 ). Buffer 500 - 46.848593625007213826\n",
      "Records in buffer 500 - 46.84862909198273\n",
      "done write example file, size 946836 - 46.92497572093271\n",
      "Done with batch 28/50 - 46.95131063798908\n",
      "Done serializing example ( 0.0019238769309595227 - 3.6654993891716003e-05 - 0.00040115206502377987 ). Buffer 500 - 48.439454247942194\n",
      "Records in buffer 500 - 48.43948423292022\n",
      "done write example file, size 947169 - 48.521705731982365\n",
      "Done with batch 29/50 - 48.548483675927855\n",
      "Done serializing example ( 0.0027345269918441772 - 5.266896914690733e-05 - 0.00045229506213217974 ). Buffer 500 - 50.1138135219225666\n",
      "Records in buffer 500 - 50.113843275932595\n",
      "done write example file, size 947075 - 50.20041133498307\n",
      "Done with batch 30/50 - 50.22779724991415\n",
      "Done serializing example ( 0.0021483880700543523 - 3.5585020668804646e-05 - 0.00036463700234889984 ). Buffer 500 - 51.786833512014716\n",
      "Records in buffer 500 - 51.78686071198899\n",
      "done write example file, size 946754 - 51.860364014981315\n",
      "Done with batch 31/50 - 51.88641015999019\n",
      "Done serializing example ( 0.003522567916661501 - 5.087105091661215e-05 - 0.0006151320412755013 ). Buffer 500 - 53.488221187028141845\n",
      "Records in buffer 500 - 53.488266856991686\n",
      "done write example file, size 946899 - 53.559091022005305\n",
      "Done with batch 32/50 - 53.59361851098947\n",
      "Done serializing example ( 0.001994210993871093 - 3.918108996003866e-05 - 0.0003910419763997197 ). Buffer 500 - 55.178902435931381424\n",
      "Records in buffer 500 - 55.17893054301385\n",
      "done write example file, size 946657 - 55.24940794194117\n",
      "Done with batch 33/50 - 55.2755583539838\n",
      "Done serializing example ( 0.002567242016084492 - 4.1353050619363785e-05 - 0.0003978189779445529 ). Buffer 500 - 56.80138187098782586\n",
      "Records in buffer 500 - 56.801410496933386\n",
      "done write example file, size 947379 - 56.87564050091896\n",
      "Done with batch 34/50 - 56.90503620298114\n",
      "Done serializing example ( 0.002119045937433839 - 3.3800024539232254e-05 - 0.00037089502438902855 ). Buffer 500 - 58.4265517019666765\n",
      "Records in buffer 500 - 58.42657920194324\n",
      "done write example file, size 947108 - 58.499090099008754\n",
      "Done with batch 35/50 - 58.53850830195006\n",
      "Done serializing example ( 0.002266056020744145 - 3.7348014302551746e-05 - 0.0003917180001735687 ). Buffer 500 - 60.10963526892013176\n",
      "Records in buffer 500 - 60.10966366401408\n",
      "done write example file, size 947236 - 60.184910038951784\n",
      "Done with batch 36/50 - 60.21203098597471\n",
      "Done serializing example ( 0.0020854490576311946 - 3.655895125120878e-05 - 0.0003912330139428377 ). Buffer 500 - 61.78108638001141464\n",
      "Records in buffer 500 - 61.781119209947065\n",
      "done write example file, size 946964 - 61.84899394097738\n",
      "Done with batch 37/50 - 61.876773176016286\n",
      "Done serializing example ( 0.004150310065597296 - 5.363696254789829e-05 - 0.0004414169816300273 ). Buffer 500 - 63.429784650914375556\n",
      "Records in buffer 500 - 63.429814029019326\n",
      "done write example file, size 947008 - 63.50288127094973\n",
      "Done with batch 38/50 - 63.529535782989115\n",
      "Done serializing example ( 0.0019316079560667276 - 3.476603887975216e-05 - 0.00039934494998306036 ). Buffer 500 - 65.055043442989738\n",
      "Records in buffer 500 - 65.05507261794992\n",
      "done write example file, size 946827 - 65.12429347995203\n",
      "Done with batch 39/50 - 65.15336502995342\n",
      "Done serializing example ( 0.0028826199704781175 - 4.0326034650206566e-05 - 0.00039995997212827206 ). Buffer 500 - 66.69898091594223\n",
      "Records in buffer 500 - 66.69900997995865\n",
      "done write example file, size 946927 - 66.7702978629386\n",
      "Done with batch 40/50 - 66.79671214194968\n",
      "Done serializing example ( 0.0031653960468247533 - 4.143000114709139e-05 - 0.0003935470012947917 ). Buffer 500 - 68.3534631609218261\n",
      "Records in buffer 500 - 68.35351259098388\n",
      "done write example file, size 947020 - 68.43551653402392\n",
      "Done with batch 41/50 - 68.4645094210282\n",
      "Done serializing example ( 0.003098459099419415 - 4.29799547418952e-05 - 0.0003995660226792097 ). Buffer 500 - 70.054604755947378118\n",
      "Records in buffer 500 - 70.05463935702574\n",
      "done write example file, size 947425 - 70.1246861909749\n",
      "Done with batch 42/50 - 70.15179674292449\n",
      "Done serializing example ( 0.003592767985537648 - 5.576200783252716e-05 - 0.0005884780548512936 ). Buffer 500 - 71.71931166294962564\n",
      "Records in buffer 500 - 71.71934621792752\n",
      "done write example file, size 947053 - 71.78667863900773\n",
      "Done with batch 43/50 - 71.8138728889171\n",
      "Done serializing example ( 0.002376966062001884 - 3.8973987102508545e-05 - 0.0004025920061394572 ). Buffer 500 - 73.4713630930055647\n",
      "Records in buffer 500 - 73.47139819094446\n",
      "done write example file, size 947256 - 73.54398341896012\n",
      "Done with batch 44/50 - 73.57318776100874\n",
      "Done serializing example ( 0.0029609210323542356 - 4.388997331261635e-05 - 0.00042860000394284725 ). Buffer 500 - 75.134647520957515\n",
      "Records in buffer 500 - 75.1346843119245\n",
      "done write example file, size 946900 - 75.20294471597299\n",
      "Done with batch 45/50 - 75.23143361695111\n",
      "Done serializing example ( 0.0017287200316786766 - 3.170897252857685e-05 - 0.00046368606854230165 ). Buffer 500 - 76.780298948986467\n",
      "Records in buffer 500 - 76.78032807598356\n",
      "done write example file, size 947190 - 76.85097717994358\n",
      "Done with batch 46/50 - 76.88036960596219\n",
      "Done serializing example ( 0.002958258963190019 - 4.48060454800725e-05 - 0.0005317139439284801 ). Buffer 500 - 78.396587949944667765\n",
      "Records in buffer 500 - 78.39661725796759\n",
      "done write example file, size 947280 - 78.47868993191514\n",
      "Done with batch 47/50 - 78.51220481295604\n",
      "Done serializing example ( 0.003597122966311872 - 5.00440364703536e-05 - 0.00040609599091112614 ). Buffer 500 - 80.13081537792459482\n",
      "Records in buffer 500 - 80.13084552797955\n",
      "done write example file, size 947146 - 80.21845515398309\n",
      "Done with batch 48/50 - 80.24629614898004\n",
      "Done serializing example ( 0.0019094430608674884 - 4.999700468033552e-05 - 0.00038184295408427715 ). Buffer 500 - 81.803289687028156\n",
      "Records in buffer 500 - 81.80331835197285\n",
      "done write example file, size 947098 - 81.88470394001342\n",
      "Done with batch 49/50 - 81.91020553791896\n",
      "Done serializing example ( 0.002483737072907388 - 4.011194687336683e-05 - 0.00039720104541629553 ). Buffer 500 - 83.4771111089503495\n",
      "Records in buffer 500 - 83.47714073595125\n",
      "done write example file, size 947091 - 83.5483265100047\n",
      "Done with batch 50/50 - 83.57643589901272\n",
      "\n",
      "total time is : 83.57646736002062\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def process_examples(records,prefix=\"\"):\n",
    "    starttime = timeit.default_timer()\n",
    "    total_training = len(records)\n",
    "    print(f\"Total of {total_training} elements\")\n",
    "    total_batches = math.floor(total_training / tf_record_file_size)\n",
    "    if total_training % tf_record_file_size != 0:\n",
    "        total_batches += 1 \n",
    "    print(f\"Total of {total_batches} files of {tf_record_file_size} records - {timeit.default_timer() - starttime}\")\n",
    "\n",
    "    counter = 0\n",
    "    file_counter = 0\n",
    "    buffer = []\n",
    "    file_list = []\n",
    "    for i in range(total_training):\n",
    "        counter += 1\n",
    "        prev_t = timeit.default_timer() - starttime\n",
    "        sentence_embedding = embed([records[i][\"text\"]])\n",
    "        emb_t = timeit.default_timer() - starttime - prev_t\n",
    "        label_encoded = encode_label(records[i][\"label\"])\n",
    "        lab_t = timeit.default_timer() - starttime - prev_t - emb_t\n",
    "        record = serialize_example(label_encoded, sentence_embedding)\n",
    "        rec_t = timeit.default_timer() - starttime - prev_t - emb_t - lab_t\n",
    "        buffer.append(record)\n",
    "        print(f\"\\rDone serializing example ( {emb_t} - {lab_t} - {rec_t} ). Buffer {len(buffer)} - {timeit.default_timer() - starttime}\",end=\"\")\n",
    "\n",
    "        if len(buffer) >= tf_record_file_size:\n",
    "            print(\"\")\n",
    "            print(f\"Records in buffer {len(buffer)} - {timeit.default_timer() - starttime}\")\n",
    "            # save this buffer of examples as a file to MinIO\n",
    "            counter = 0\n",
    "            file_counter+=1\n",
    "            file_name = f\"{prefix}_file{file_counter}.tfrecord\"\n",
    "            with open(file_name,\"w+\") as f:\n",
    "                with tf.io.TFRecordWriter(f.name,options=\"GZIP\") as writer:\n",
    "                    for example in buffer:\n",
    "                        writer.write(example.SerializeToString())\n",
    "            print(f\"done write example file, size {os.stat(file_name).st_size} - {timeit.default_timer() - starttime}\")\n",
    "            try:\n",
    "                minioClient.fput_object(datasets_bucket, f\"{preprocessed_data_folder}/{file_name}\", file_name)\n",
    "            except S3Error as err:\n",
    "                print(err)\n",
    "            file_list.append(file_name)\n",
    "            os.remove(file_name)\n",
    "            buffer=[]\n",
    "            print(f\"Done with batch {file_counter}/{total_batches} - {timeit.default_timer() - starttime}\")\n",
    "    print(\"\")\n",
    "    if len(buffer) > 0:\n",
    "        file_counter+=1\n",
    "        file_name = f\"file{file_counter}.tfrecord\"\n",
    "        with open(file_name,\"w+\") as f:\n",
    "            with tf.io.TFRecordWriter(f.name) as writer:\n",
    "                for example in buffer:\n",
    "                    writer.write(example.SerializeToString())\n",
    "        try:\n",
    "            minioClient.fput_object(datasets_bucket, f\"{preprocessed_data_folder}/{file_name}\", file_name)\n",
    "        except S3Error as err:\n",
    "            print(err)\n",
    "        file_list.append(file_name)\n",
    "        os.remove(file_name)\n",
    "        buffer=[]\n",
    "    print(\"total time is :\", timeit.default_timer() - starttime)\n",
    "    return file_list\n",
    "process_examples(train,prefix=\"train\")\n",
    "process_examples(test,prefix=\"test\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this point we are done preprocessing our data. We have a set of `.tfrecord` files stored on our bucket. We will now feed that to the model allowing it to consume and train concurrently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are going to get a list of files (training data) from MinIO. Technically the pre-processing stage and the training stage could be completely decoupled so it's a good idea to list the file chunks we have in bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# List all training tfrecord files\n",
    "objects = minioClient.list_objects(datasets_bucket, prefix=f\"{preprocessed_data_folder}/train\")\n",
    "training_files_list = []\n",
    "for obj in objects:\n",
    "    training_files_list.append(obj.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# List all testing tfrecord files\n",
    "objects = minioClient.list_objects(datasets_bucket, prefix=f\"{preprocessed_data_folder}/test\")\n",
    "testing_files_list = []\n",
    "for obj in objects:\n",
    "    testing_files_list.append(obj.object_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to have `TensorFlow` connect to MinIO we are going to tell it the location and connection details of our MinIO instance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = minio_access_key\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = minio_secret_key\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "os.environ[\"S3_ENDPOINT\"] = minio_address\n",
    "os.environ[\"S3_USE_HTTPS\"] = \"0\"\n",
    "os.environ[\"S3_VERIFY_SSL\"] = \"0\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let us create a `tf.data.Dataset` that loads records from our files on MinIO as they become needed. To do that we are going to take the list of files we have and format them in a way that references the location of the actual objects. We will do this for the testing dataset as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_training_filenames = [f\"s3://datasets/{f}\" for f in training_files_list]\n",
    "testing_filenames = [f\"s3://datasets/{f}\" for f in testing_files_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following step is optional, but I recommend it. I am going to split my training dataset into two sets, `90%` of the data for training and `10%` of the data for validation, the model won't learn on the validation data but it will help the model train better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_train_data_files = math.floor(len(all_training_filenames)*0.9)\n",
    "if total_train_data_files == len(all_training_filenames):\n",
    "    total_train_data_files -= 1\n",
    "training_files = all_training_filenames[0:total_train_data_files]\n",
    "validation_files = all_training_filenames[total_train_data_files:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's create the `tf.data` datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "ignore_order = tf.data.Options()\n",
    "ignore_order.experimental_deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(training_files,num_parallel_reads=AUTO,compression_type=\"GZIP\")\n",
    "dataset = dataset.with_options(ignore_order)\n",
    "\n",
    "validation = tf.data.TFRecordDataset(validation_files,num_parallel_reads=AUTO,compression_type=\"GZIP\")\n",
    "validation = validation.with_options(ignore_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testing_dataset = tf.data.TFRecordDataset(testing_filenames,num_parallel_reads=AUTO,compression_type=\"GZIP\")\n",
    "testing_dataset = testing_dataset.with_options(ignore_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to decode our `TFRecord` encoded files we are going to need a decoding function that does the exact opposite of our `serialize_example` function. Since the data coming out of the `TFRecord` has shape `(512,)` and `(2,)` respectively, we are going to reshape it as well since that's the format our model will be expecting to receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_fn(record_bytes): \n",
    "    schema = {\n",
    "        \"label\": tf.io.FixedLenFeature([2], dtype=tf.int64), \n",
    "        \"sentence\": tf.io.FixedLenFeature([512], dtype=tf.float32),\n",
    "        }\n",
    "    \n",
    "    tf_example = tf.io.parse_single_example(record_bytes,schema) \n",
    "    new_shape = tf.reshape(tf_example[\"sentence\"],[1,512])\n",
    "    label = tf.reshape(tf_example[\"label\"],[1,2])\n",
    "    return new_shape,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's build our model, nothing fancy, I'm just going to use a couple of Dense layers with a [softmax](https://en.wikipedia.org/wiki/Softmax_function) activation at the end.  We are trying to predict whether the input is `positive` or `negative` so we are going to get probabilities of the likelihood of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "  keras.layers.Dense(\n",
    "    units=256,\n",
    "    input_shape=(1,512 ),\n",
    "    activation=\"relu\"\n",
    "  )\n",
    ")\n",
    "model.add(\n",
    "  keras.layers.Dropout(rate=0.5)\n",
    ")\n",
    "\n",
    "model.add(\n",
    "  keras.layers.Dense(\n",
    "    units=16,\n",
    "    activation=\"relu\"\n",
    "  )\n",
    ")\n",
    "model.add(\n",
    "  keras.layers.Dropout(rate=0.5)\n",
    ")\n",
    "\n",
    "model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Structure of our Deep Learning model](pic2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1, 16)             4112      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1, 2)              34        \n",
      "=================================================================\n",
      "Total params: 135,474\n",
      "Trainable params: 135,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's prepare our datasets for the training stage by having them repeat themselves a little and batch `128` items at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mapped_ds = dataset.map(decode_fn)\n",
    "mapped_ds = mapped_ds.repeat(5)\n",
    "mapped_ds = mapped_ds.batch(128)\n",
    "\n",
    "mapped_validation = validation.map(decode_fn)\n",
    "mapped_validation = mapped_validation.repeat(5)\n",
    "mapped_validation = mapped_validation.batch(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testing_mapped_ds = testing_dataset.map(decode_fn)\n",
    "testing_mapped_ds = testing_mapped_ds.repeat(5)\n",
    "testing_mapped_ds = testing_mapped_ds.batch(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we train we wanna make sure to store checkpoints of our model in case the training gets interrupted and we wanna resume where we left off, so we are going to use the keras callback `tf.keras.callbacks.ModelCheckpoint` to have TensorFlow save the checkpoint to `MinIO` after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = f\"s3://{datasets_bucket}/checkpoints/cp.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We also want to save the `TensorBoard`  histograms so we are going to add a callback to store those in our bucket under the `logs/imdb/` prefix. We are identifying this run with a `model_note` and the current time, this is so we can tell apart different instances of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 17:02:19.232373: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-08-12 17:02:19.232419: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-08-12 17:02:19.232432: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-08-12 17:02:19.232448: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    }
   ],
   "source": [
    "model_note=\"256\"\n",
    "logdir = f\"s3://{datasets_bucket}/logs/imdb/{model_note}-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally we will train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      2/Unknown - 0s 77ms/step - loss: 0.6929 - accuracy: 0.4961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 17:02:22.236338: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-08-12 17:02:22.236379: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-08-12 17:02:22.236389: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-08-12 17:02:22.246949: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-08-12 17:02:22.248792: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 0 callback api events and 0 activity events.\n",
      "2022-08-12 17:02:22.303377: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22\n",
      "2022-08-12 17:02:22.318122: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22/chika.trace.json.gz\n",
      "2022-08-12 17:02:22.321446: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.001 ms\n",
      "\n",
      "2022-08-12 17:02:22.378910: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22Dumped tool data for overview_page.pb to s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22/chika.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22/chika.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22/chika.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to s3://datasets/logs/imdb/256-20220812-170219/train/plugins/profile/2022_08_12_17_02_22/chika.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    876/Unknown - 8s 9ms/step - loss: 0.3664 - accuracy: 0.8448\n",
      "Epoch 00001: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.3662 - accuracy: 0.8449 - val_loss: 0.3199 - val_accuracy: 0.8644\n",
      "Epoch 2/10\n",
      "876/879 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.8749\n",
      "Epoch 00002: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.3126 - accuracy: 0.8750 - val_loss: 0.3112 - val_accuracy: 0.8676\n",
      "Epoch 3/10\n",
      "877/879 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.8943\n",
      "Epoch 00003: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.2736 - accuracy: 0.8944 - val_loss: 0.3164 - val_accuracy: 0.8720\n",
      "Epoch 4/10\n",
      "877/879 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9120\n",
      "Epoch 00004: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.2328 - accuracy: 0.9121 - val_loss: 0.3341 - val_accuracy: 0.8684\n",
      "Epoch 5/10\n",
      "876/879 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9288\n",
      "Epoch 00005: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.1949 - accuracy: 0.9289 - val_loss: 0.3500 - val_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "878/879 [============================>.] - ETA: 0s - loss: 0.1661 - accuracy: 0.9390\n",
      "Epoch 00006: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.1661 - accuracy: 0.9390 - val_loss: 0.3867 - val_accuracy: 0.8688\n",
      "Epoch 7/10\n",
      "874/879 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9482\n",
      "Epoch 00007: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.1431 - accuracy: 0.9482 - val_loss: 0.4298 - val_accuracy: 0.8716\n",
      "Epoch 8/10\n",
      "874/879 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9552\n",
      "Epoch 00008: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.1258 - accuracy: 0.9553 - val_loss: 0.4542 - val_accuracy: 0.8752\n",
      "Epoch 9/10\n",
      "875/879 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9608\n",
      "Epoch 00009: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.1113 - accuracy: 0.9609 - val_loss: 0.4750 - val_accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "876/879 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9641\n",
      "Epoch 00010: saving model to s3://datasets/checkpoints/cp.ckpt\n",
      "879/879 [==============================] - 9s 10ms/step - loss: 0.1012 - accuracy: 0.9641 - val_loss: 0.5127 - val_accuracy: 0.8648\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    mapped_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[cp_callback, tensorboard_callback],\n",
    "    validation_data=mapped_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we run `mc admin trace myminio` we can see TensorFlow reading the data straight from MinIO, but only the parts it needs:\n",
    "\n",
    "![mc admin trace](pic3.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have our model, we want to save it to MinIO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "model_destination = f\"s3://{datasets_bucket}/imdb_sentiment_analysis/1\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 17:04:19.557858: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dvaldivia/anaconda3/envs/mlp37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: s3://datasets/imdb_sentiment_analysis/1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(model_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "keys = history.history.keys()\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "if \"val_accuracy\" in keys:\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history[\"loss\"])\n",
    "if \"val_loss\" in keys:\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's test our model and see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 [==============================] - 7s 7ms/step - loss: 0.5748 - accuracy: 0.8503\n"
     ]
    }
   ],
   "source": [
    "testing = model.evaluate(testing_mapped_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This returns 85.63% accuracy, not state of the art, but also not bad for such a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's run `TensorBoard` to explore our models loading the data straight from MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```bash\n",
    "AWS_ACCESS_KEY_ID=minioadmin AWS_SECRET_ACCESS_KEY=minioadmin AWS_REGION=us-east-1 S3_ENDPOINT=localhost:9000 S3_USE_HTTPS=0 S3_VERIFY_SSL=0 tensorboard --logdir s3://datasets/logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then go to `http://localhost:6006` on your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![TensorBoard](pic4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can play with our model and see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"This movie sucks\",\n",
    "    \"This was extremely good, I loved it.\",\n",
    "    \"great acting\",\n",
    "    \"terrible acting\",\n",
    "    \"pure kahoot\",\n",
    "    \"I don't know what's the point of this movie, this movie sucks but the acting is great\",\n",
    "    \"This is not a good movie\",\n",
    "]\n",
    "sample_embedded = embed(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 512) for input Tensor(\"dense_3_input:0\", shape=(None, 1, 512), dtype=float32), but it was called on an input with incompatible shape (None, 512).\n",
      "This movie sucks - negative\n",
      "This was extremely good, I loved it. - positive\n",
      "great acting - negative\n",
      "terrible acting - negative\n",
      "pure kahoot - positive\n",
      "I don't know what's the point of this movie, this movie sucks but the acting is great - negative\n",
      "This is not a good movie - negative\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(sample_embedded)\n",
    "for s in range(len(samples)):\n",
    "    if res[s][0] > res[s][1]:\n",
    "        print(f\"{samples[s]} - positive\")\n",
    "    else:\n",
    "        print(f\"{samples[s]} - negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Serving the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can explore model using `saved_model_cli` and check the types of inputs the model expects (which we already know from the design) but it's a decent way to see if our model is ready for TensorFlow serve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['__saved_model_init_op']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['__saved_model_init_op'] tensor_info:\r\n",
      "        dtype: DT_INVALID\r\n",
      "        shape: unknown_rank\r\n",
      "        name: NoOp\r\n",
      "  Method name is: \r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['dense_3_input'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 1, 512)\r\n",
      "        name: serving_default_dense_3_input:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['dense_5'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 1, 2)\r\n",
      "        name: StatefulPartitionedCall:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n",
      "WARNING:tensorflow:From /home/dvaldivia/anaconda3/envs/mlp37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "If using Keras pass *_constraint arguments to layers.\r\n",
      "\r\n",
      "Defined Functions:\r\n",
      "  Function Name: '__call__'\r\n",
      "    Option #1\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #2\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          dense_3_input: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='dense_3_input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #3\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          dense_3_input: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='dense_3_input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #4\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "\r\n",
      "  Function Name: '_default_save_signature'\r\n",
      "    Option #1\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          dense_3_input: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='dense_3_input')\r\n",
      "\r\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\r\n",
      "    Option #1\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #2\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          inputs: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='inputs')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #3\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          dense_3_input: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='dense_3_input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: True\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n",
      "    Option #4\r\n",
      "      Callable with:\r\n",
      "        Argument #1\r\n",
      "          dense_3_input: TensorSpec(shape=(None, 1, 512), dtype=tf.float32, name='dense_3_input')\r\n",
      "        Argument #2\r\n",
      "          DType: bool\r\n",
      "          Value: False\r\n",
      "        Argument #3\r\n",
      "          DType: NoneType\r\n",
      "          Value: None\r\n"
     ]
    }
   ],
   "source": [
    "!export AWS_ACCESS_KEY_ID={minio_access_key}\n",
    "!export AWS_SECRET_ACCESS_KEY={minio_secret_key}\n",
    "!export AWS_REGION=\"us-east-1\"\n",
    "!export S3_ENDPOINT={minio_address}\n",
    "!export S3_USE_HTTPS=\"0\"\n",
    "!export S3_VERIFY_SSL=\"0\"\n",
    "\n",
    "!saved_model_cli show --dir s3://{datasets_bucket}/imdb_sentiment_analysis --all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To test the model during this \"development\" stage, we are going to use the `tensorflow/serving` container image to keep things simple. So let's fireup our container and have it pull the model from MinIO. By default TensorFlow Serve exposes a `gRPC` interface on port `8500` but for the sake of example we will be using the REST endpoint by passing `--rest_api_port=8501` so that we can play with the server from this notebook or using curl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/my-model-served\" is already in use by container \"cb32c96197049924dcb1fddd8492bc76b30a4b2a7b388eb629417fbbacc34b61\". You have to remove (or rename) that container to be able to reuse that name.\r\n",
      "See 'docker run --help'.\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 8500:8500 \\\n",
    "  -p 8501:8501 \\\n",
    "  --name my-model-served \\\n",
    "  -it \\\n",
    "  --detach \\\n",
    "  -e  AWS_ACCESS_KEY_ID=\"minioadmin\" \\\n",
    "  -e  AWS_SECRET_ACCESS_KEY=\"minioadmin\" \\\n",
    "  -e  AWS_REGION=\"us-east-1\" \\\n",
    "  -e  S3_ENDPOINT=\"host.docker.internal:9000\" \\\n",
    "  -e  S3_USE_HTTPS=\"0\" \\\n",
    "  -e  S3_VERIFY_SSL=\"0\" \\\n",
    "  --add-host=host.docker.internal:host-gateway \\\n",
    "  --entrypoint=tensorflow_model_server \\\n",
    "  tensorflow/serving \\\n",
    "  --enable_batching \\\n",
    "  --port=8500 \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=sentiment-analysis \\\n",
    "  --model_base_path=\"s3://datasets/imdb_sentiment_analysis\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's play with the tensorflow model serve server (had to go for it).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "  \"model_version_status\": [\n",
      "    {\n",
      "      \"version\": \"1\",\n",
      "      \"state\": \"AVAILABLE\",\n",
      "      \"status\": {\n",
      "        \"error_code\": \"OK\",\n",
      "        \"error_message\": \"\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "x = requests.get('http://localhost:8501/v1/models/sentiment-analysis')\n",
    "print(x.status_code)\n",
    "print(json.dumps(json.loads(x.content),indent=2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks our model is ready to `serve` hahaha, let's encode one of our senteces as a `(-1, 1, 512)` input and beam it to our server"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "encoded_sentence = embed([\"I loved the movie\",\n",
    "                          \"I hated the movie\"]),\n",
    "for inp in encoded_sentence[0].numpy():\n",
    "    print(len(inp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "  \"outputs\": [\n",
      "    [\n",
      "      [\n",
      "        3.95081809e-18,\n",
      "        1.0\n",
      "      ],\n",
      "      [\n",
      "        0.999999166,\n",
      "        8.59868067e-07\n",
      "      ],\n",
      "      [\n",
      "        1.2191056e-07,\n",
      "        0.999999881\n",
      "      ],\n",
      "      [\n",
      "        4.76984378e-14,\n",
      "        1.0\n",
      "      ],\n",
      "      [\n",
      "        1.0,\n",
      "        1.87321048e-10\n",
      "      ],\n",
      "      [\n",
      "        5.32020174e-14,\n",
      "        1.0\n",
      "      ],\n",
      "      [\n",
      "        3.15164338e-27,\n",
      "        1.0\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "---Pretty Printing Results---\n",
      "This movie sucks - negative\n",
      "This was extremely good, I loved it. - positive\n",
      "great acting - negative\n",
      "terrible acting - negative\n",
      "pure kahoot - positive\n",
      "I don't know what's the point of this movie, this movie sucks but the acting is great - negative\n",
      "This is not a good movie - negative\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"This movie sucks\",\n",
    "    \"This was extremely good, I loved it.\",\n",
    "    \"great acting\",\n",
    "    \"terrible acting\",\n",
    "    \"pure kahoot\",\n",
    "    \"I don't know what's the point of this movie, this movie sucks but the acting is great\",\n",
    "    \"This is not a good movie\",\n",
    "]\n",
    "\n",
    "encoded_sentence = embed(samples),\n",
    "input_sentences = []\n",
    "for inp in encoded_sentence[0].numpy():\n",
    "    input_sentences.append(inp.tolist())\n",
    "input = {\n",
    "    \"inputs\":[\n",
    "        input_sentences\n",
    "    ]\n",
    "}\n",
    "\n",
    "x = requests.post('http://localhost:8501/v1/models/sentiment-analysis:predict',json.dumps(input))\n",
    "print(x.status_code)\n",
    "if x.status_code >= 400:\n",
    "    print(x.content)\n",
    "else:\n",
    "    print(json.dumps(json.loads(x.content),indent=2))\n",
    "    print(\"---Pretty Printing Results---\")\n",
    "    serve_response = json.loads(x.content)\n",
    "    for i in range(len(serve_response['outputs'][0])):\n",
    "        if serve_response['outputs'][0][i][0] > serve_response['outputs'][0][i][1]:\n",
    "            print(f\"{samples[i]} - positive\")\n",
    "        else:\n",
    "            print(f\"{samples[i]} - negative\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As demonstrated, you can build large scale AI/ML pipelines that can rely entirely on MinIO. This is a function of both MinIO's performance charateristics but also its ability to seamlessly scale to Petabytes and Exabytes of data. By separating storage and compute, one can build a framework that is not dependant on local resources - allowing you to run them on a container inside Kubernetes. This adds considerable flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can see how TensorFlow was able to load the data as it was needed and no customization was needed at all, it simply worked. Moreover this approach could be quickly extended to training by running [TensorFlow in a distributed](https://www.tensorflow.org/guide/distributed_training) manner. This ensures there is very little data to shuffle over the network between training nodes as MinIO becomes the sole source of that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright MinIO 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}